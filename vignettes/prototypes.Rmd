---
title: "Permutation tests for adaptive designs"
subtitle: "Prototypes for experimental package features"
author: Florian Klinglmueller
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Vignette Title}
  \usepackage[utf8]{inputenc}
---

```{r}
library(magrittr)
library(plyr)
library(dplyr)
library(pander)
library(parallel)
library(bt88.03.704)
library(adaperm)
options(mc.cores=detectCores()-1)
```

# Adjusted p-values

Let $T_{(1)},...,T_{(|G|)}$ the ordered resampling test statistics of
the pre-planned test. Then the $p$-value of the test following an
adaptive interim analysis is given by $\tilde{p} = 1-\frac{r^*}{|\G|}$
where

$$
r^*=\min \{ r : \pe \leq A(T_{(r)})\}
$$


and $A(t)$ is defined as the conditional survival function of the
preplanned test given the first stage treatment assignments:

This is easily computed:

```{r}

sim_pvals <- function(B,delta,nulldist=rnorm,...){
    replicate(B,{
                  x1 <- nulldist(10,...)+rep(0:1,5)*delta
                  x2 <- nulldist(10,...)+rep(0:1,5)*delta
                  xE <- nulldist(6,...)+rep(0:1,3)*delta
                  pt <- t.test(c(x1,x2,xE)~rep(0:1,13),alternative='less',var.equal=T)$p.value
                  pdist  <- perm_dist(x1,x2,rep(0:1,5),rep(0:1,5),ranksum,B=10000)
                  pw <- wilcox.test(c(x1,x2,xE)~rep(0:1,13),alternative='less')$p.value
                  cdist <- adaperm:::cond_dist(x1,x2,rep(0:1,5),rep(0:1,5),ranksum,B=10000)
                  edist <- perm_dist(x2,xE,rep(0:1,5),rep(0:1,3),ranksum,B=10000)
                  t2 <- ranksum(c(x2,xE),rep(0:1,8))
                  c(sum(pdist>=quantile(cdist,sum(edist<t2)/length(edist)))/length(pdist),pt,pw)
              })
    }


pval_dist <- sim_pvals(1000,1,rnorm_cont,csd=10)
head(t(pval_dist))
cor(t(pval_dist)[,c(1,3)])
plot(t(pval_dist)[,c(1,3)])
par(mfrow=c(3,1))
plot(sort(pval_dist[1,]),seq(0,1,length.out=1000))
plot(sort(pval_dist[2,]),seq(0,1,length.out=1000))
plot(sort(pval_dist[3,]),seq(0,1,length.out=1000))

## lookin good!
rowSums(pval_dist<.05)/1000
hist(pval_dist[1,])



adaptive_permtest_ts <- function(x1,x2,xE,g1,g2,gE,stat,permutations=10000){
    pdist  <- perm_dist(x1,x2,g1,g2,stat,B=permutations)
    cdist <- adaperm:::cond_dist(x1,x2,g1,g2,stat,B=permutations)
    edist <- perm_dist(x2,xE,g2,gE,stat,B=permutations)
    t2 <- stat(c(x2,xE),c(g2,gE))
    pval <- sum(pdist>=quantile(cdist,sum(edist<t2)/length(edist)))/length(pdist)
    names(t2) <- deparse(substitute(stat))
    out <- list(statistic = t2,
                parameter = c('permutations'=permutations),
                p.value = pval,
                alternative = "one.sided",
                null.value = c("distribution of treated samples"='different from control samples'),
                data.name = paste(deparse(substitute(c(x1,x2,xE,g1,g2,gE))),collapse=', '),
                method = "Two-sample permutation test for adaptive designs")
    class(out) <- 'htest'
    out
}

str(t.test(rnorm(10)))
t.test(rnorm(10))
adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,maritzm)
adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,ranksum)

str(adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,maritzm))



```

# Robus m-Tests based on maritz' m-estimator

Maritz et al. and Rosenbaum suggest the use of an $m$-estimator
(Huber) for use with a rerandomization test. In `adaperm` we have
implemented such a test statistic in the function `maritzm`.



```{r}
compare_adaptive_tests <- function(n1,n,rule,rdist,test_statistic,mpfr=F,resam=100,perms=100,...){
    x <- rdist(n,...)
    ne <- rule(x[1:n1])
    if(ne>n){
        x <- c(x,rdist(ne-n,...))
    } else {
        ne <- n
    }
    list(ne = ne,
         permtestT = adaptive_permtest_os(x,n1,n,ne,diffmean,perms=perms),
         invnormT = adaptive_invnorm_ttest_os(x,n1,n,ne),
         permtestW = adaptive_permtest_os(x,n1,n,ne,signedranks,perms=perms),
         invnormW = adaptive_invnorm_wilcoxtest_os(x,n1,n,ne),
         permtestM = adaptive_permtest_os(x,n1,n,ne,maritzm,perms=perms))
}

##' Compare operating characteristics for a number of one-sample tests
##'
##' \code{test_funs} needs to be a list of functions that take arguments \code{x,n1,n,ne,permutations} and return \code{TRUE} of \code{FALSE} depending on whether the corresponding decision rule rejects the null hypothesis or not.
##'
##' \code{rule} needs to be a function that takes as argument the vector of first stage observations and return an interger number, which (if larger than \code{n}) will be used as the new total sample size.
##' 
##' @title Compare one-sample test procedures
##' @param test_funs list of test functions (see Details)
##' @param n1 first stage sample size
##' @param n pre-planned total sample size
##' @param rule sample size reassessment rule (see Details)
##' @param rdist distribution from which to draw observations 
##' @param ... additional arguments to rdist
##' @return let's see
##' @author Florian Klinglmueller
compare_tests_onesample <- function(B,test_funs,n1,n,rule,rdist,...){
    run <- function(test_funs,n1,n,rule,rdist,...){
        x <- rdist(n,...)
        ne <- rule(x[1:n1])
        if(ne>n){
            x <- c(x,rdist(ne-n,...))
        } else {
            ne <- n
        }
        c(n1=n1,n=n,ne=ne,lapply(test_funs,do.call,list(x,n1,n,ne)))
    }
    results <- mclapply2(1:B,function(i) run(test_funs,n1,n,rule,rdist,...))
    results %>% bind_rows -> results
    eval(expr=parse(text=paste0("summarize(results,ASN=mean(ne),maxSN=max(ne),sdSN=sd(ne),",paste0(names(tests),"=","mean(",names(tests),")",collapse=','),")")))
}

tests <- list(
    permtestT = function(x,n1,n,ne) adaptive_permtest_os(x,n1,n,ne,diffmean,perms=10000),
    invnormT = function(x,n1,n,ne)  adaptive_invnorm_ttest_os(x,n1,n,ne),
    permtestW = function(x,n1,n,ne) adaptive_permtest_os(x,n1,n,ne,signedranks,perms=10000),
    invnormW = function(x,n1,n,ne) adaptive_invnorm_wilcoxtest_os(x,n1,n,ne),
    permtestM = function(x,n1,n,ne) adaptive_permtest_os(x,n1,n,ne,maritzm,perms=10000))

## Type I error 
compare_tests_onesample(1000,tests,10,20,cond_power_rule_norm,rnorm_cont,mean=0,sd=1.2,cshift=0,csd=3)
## Power
compare_tests_onesample(1000,tests,10,20,cond_power_rule_norm,rnorm_cont,mean=.5,sd=1,cshift=.5,csd=5)



delta <- 0
x1 <- rnorm(10)+rep(0:1,5)*delta
x2 <- rnorm(10)+rep(0:1,5)*delta
xE <- rnorm(6)+rep(0:1,3)*delta
g1 <- sign(x1);g2 <- sign(x2);gE <- sign(xE)
pt <- t.test(c(x1,x2,xE),alternative='less')$p.value
pdist  <- perm_dist(x1,x2,g1,g2,maritzm,B=10000,restricted=F)
pw <- wilcox.test(c(x1,x2,xE),alternative='less')$p.value
cdist <- adaperm:::cond_dist(x1,x2,g1,g2,maritzm,B=10000,restricted=F)
edist <- perm_dist(x2,xE,g2,gE,maritzm,B=10000,restricted=F)
t2 <- maritzm(c(x2,xE),rep(0:1,8))

c(sum(pdist>=quantile(cdist,sum(edist<t2)/length(edist)))/length(pdist),pt,pw)

adaptive_permtest_os(c(x1,x2,xE),10,20,26,maritzm,perms=10000)
permutation_CER(abs(x1),g1>0,abs(x2),maritzm,permutations=10000,restricted=F)
perm_test(abs(x2),abs(xE),g2,gE,maritzm,B=10000,restricted=F)


par(mfrow=c(3,1))
xl <- min(c(pdist,cdist,edist))
xu <- max(c(pdist,cdist,edist))
hist(pdist,xlim=c(xl,xu))
hist(cdist,xlim=c(xl,xu))
hist(edist,xlim=c(xl,xu))
abline(v=t2)



```


# Point estimates and confidence intervals

```{r}


adaptive_permtest_quick <- function(x1,x2,xE,g1,g2,gE,stat,permutations=10000){
    pdist  <- perm_dist(x1,x2,g1,g2,stat,B=permutations)
    cdist <- adaperm:::cond_dist(x1,x2,g1,g2,stat,B=permutations)
    edist <- perm_dist(x2,xE,g2,gE,stat,B=permutations)
    t2 <- stat(c(x2,xE),c(g2,gE))
    pval <- sum(pdist>=quantile(cdist,sum(edist<t2)/length(edist)))/length(pdist)
    pval
}


adaptive_permtest_ts <- function(x1,x2,xE,g1,g2,gE,stat,permutations=10000,conf_level=.05){
    pval <- adaptive_permtest_quick(x1,x2,xE,g1,g2,gE,stat,permutations=10000)
    err <- function(d,conf_level=.5){
        x1 <- x1-d*g1
        x2 <- x2-d*g2
        xE <- xE-d*gE
        adaptive_permtest_quick(x1,x2,xE,g1,g2,gE,stat,permutations=10000)-conf_level
    }
    t2 <- stat(c(x2,xE),c(g2,gE))
    names(t2) <- deparse(substitute(stat))
    ## rms
    guesstimate <- sqrt(mean(c(x1,x2,xE)^2))*sign(.5-pval)
    estimate <- c("constant additive effect"=uniroot(err,c(0,guesstimate))$root)
    conf.int <- c(uniroot(err,c(0,guesstimate*sign(conf_level-pval)),conf_level=conf_level)$root,Inf)
    attr(conf.int,"conf.level") <- 1-conf_level
    out <- list(statistic = t2,
                parameter = c('permutations'=permutations),
                p.value = pval,
                estimate = estimate,
                conf.int=conf.int,
                alternative = "one.sided",
                null.value = c("distribution of treated samples"='different from control samples'),
                data.name = paste(deparse(substitute(c(x1,x2,xE,g1,g2,gE))),collapse=', '),
                method = "Two-sample permutation test for adaptive designs")
    class(out) <- 'htest'
    out
}

g1 <- rep(0:1,5)
g2 <- rep(0:1,5)
gE <- rep(0:1,3)
x1 <- rnorm(10)+g1
x2 <- rnorm(10)+g2
xE <- rnorm(6)+gE

adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,maritzm,perm=10000)
adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,ranksum,perm=10000)
adaptive_permtest_ts(x1,x2,xE,g1,g2,gE,meandiff,perm=10000)

t.test(c(x1,x2,xE)~c(g1,g2,gE))
err(100)
uniroot(err,c(0,10))


```
