---
title: "Permutation tests for adaptive designs"
subtitle: "Refactoring of simulation studies"
author: Florian Klinglmueller
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Vignette Title}
  \usepackage[utf8]{inputenc}
---

```{r}
library(magrittr)
library(plyr)
library(dplyr)
library(reshape2)
library(ggplot2)
library(pander)
library(parallel)
library(bt88.03.704)
##devtools::install_github('floatofmath/adaperm')
library(adaperm)
options(mc.cores=detectCores()-1)

```

```{r, eval=F}
library(Rcpp)
sourceCpp("../src/combinations.cpp")
library(microbenchmark)
## about 90 fold time improvement
microbenchmark(all_combinations_cpp(16,8),gtools::combinations(16,8))
microbenchmark(all_reassignments_cpp(16,8),gtools::combinations(16,8))
null <- all_combinations(24,12)
## stress test
replicate(1000,{null <- all_combinations(20,10);NULL})

for(n in 1:24){
    for(k in 1:n){
        if(!all(t(all_combinations(n,k)) == gtools::combinations(n,k))){
            stop(paste('error at n =',n,'k =',k))
        }
    }
}
    
for(n in 1:24){
    for(k in 1:n){
        if(!all(all_reassignments_cpp(n,k) == adaperm:::all_reassignments(n,k))){
            stop(paste('error at n =',n,'k =',k))
        }
    }
}


```
# Tests under consideration

We look at three classes of tests:

1. **Inverse-normal combination tests**
   1. Equal variance $t$-test 
   2. Stage-wise Wilcoxon Rank-sum tests

2. **Permutation based conditional error tests**
   1. Permutation test using $t$-statistic
   2. Permutation test using Wilcoxon Rank-sum statistic
   3. Permutation test using Maritz-m statistic

3. **Nonparametric combination test**
   1. Permutation test using $t$-statistic
   2. Permutation test using Wilcoxon Rank-sum statistic
   3. Permutation test using Maritz-m statistic


# Distributions

Naturally we need to consider the Normal distribution. Proschan
considers the following distributions:
  
- log-gamma distribution
- t-distribution
  
Gorman considers the following distributions:
  
- uniform
- t-distribution df=4
- lambda family 
- symmetric bimodal
- skewed bimodal

For all distributions we will study a scenario under the null, and two
scenarios under the alternative - one where the *Inverse-normal
combination $t$-test* has 60% power with a preplanned total per-group
sample size of 10, the other where it achieves 80% power with a
preplanned total per-group sample size of 100. 

# Sample size reassessment

In all cases we will apply a sample size reassessment rule based on
a conditional power rule that reestimates the sample size based on an
unblinded estimate of the variance. 


# Code

## Test procedure

```{r}
x <- rnorm(20)
y <- rnorm(20)

adaptive_invnormtest_2s(x,y,n1=8,n=16,ne=20)
adaptive_invnorm_wilcoxtest_2s(x,y,n1=8,n=16,ne=20)
adaperm_DR(c(x,y),rep(0:1,each=20),n1=8,n=16,test=tstat,cer_type='randomized',atest_type='midp')
adaperm_DR(c(x,y),rep(0:1,each=20),n1=8,n=16,test=ranksum,cer_type='randomized',atest_type='midp')
adaperm_DR(c(x,y),rep(0:1,each=20),n1=8,n=16,test=maritzm,cer_type='randomized',atest_type='midp')
    
```

## Distributions

### Small sample scenarios

```{r,eval=F}
x <- rnorm(10)
y <- rnorm(10)
adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)

## Assume m0 = 1 s0=.75 (power=80), true m0=1 s0=.9 (power=60)
power.t.test(10,1,.6)
mean(replicate(10000,{
sd <- .9
x <- rnorm(10,sd=sd)
y <- rnorm(10,m=1,sd=sd)
adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)}))


x <- log(rgamma(10,1))
y <- log(rgamma(10,1))
adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)


mean(replicate(10000,{a <- 1
                      ncp <- 1.35
                      x <- log(rgamma(10,a))
                      y <- log(rgamma(10,a))+ncp
                      adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)}))

x <- rt(10,4)
y <- rt(10,4)
adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)

mean(replicate(10000,{ncp <- 1.2
                      x <- rt(10,4)
                      y <- rt(10,4,ncp)
                      adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)}))

mean(replicate(10000,{sd <- .8
                      x <- rnorm_cont(10,0,sd,cshift=0,csd=3*sd)
                      y <- rnorm_cont(10,1,sd,cshift=1,csd=3*sd)
                      adaptive_invnormtest_2s(x,y,n1=5,n=10,ne=10)}))


r_counts <- function(n,theta=1,df=2,lambda=NULL){
  if (is.null(lambda)) lambda=rchisq(n=n,df = df)
  lambda[lambda<.5]=.5
  lambda[lambda>10000]=10000
  y=rpois(n = n,lambda = lambda*theta)
  y
}


```

This concludes the configuration of the small sample setup.

In all situations our planning assumption is normally distributed
observations with mean difference of $\delta_0=1$ and common standard deviation
of $\sigma_0=.6$ but simulate data from. Note that for these small
sample sizes there is quite a large difference in power between the
the inverse normal combination and the fixed sample t-test, the latter
has a power of 94% for $\sigma_0=.6$.

1. Normal distributions with mean-differences $\delta=1$ and $\sigma=.9$
2. Log-gamma distirbiutions with shape parameter $a=1$ shifted by
   $\delta=1.35$ in the treatment group
3. $t$-distributions with $4$ degrees of freedom and non-centrality
   parameter $1.2$ in the treatment group

in all cases the inverse normal combination test has a (simulated)
power of 60%.

### Large sample scenarios

```{r,eval=F}
x <- rnorm(100)
y <- rnorm(100)
adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)

## Assume m0 = 1 s0=2.5 (power=80), true m0=1 s0=3.2 (power=60)
power.t.test(100,1,2.5)

mean(replicate(10000,{
sd <- 3.2
x <- rnorm(100,sd=sd)
y <- rnorm(100,m=1,sd=sd)
adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)}))


x <- log(rgamma(100,1))
y <- log(rgamma(100,1))
adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)


mean(replicate(10000,{a <- 1
                      ncp <- .4
                      x <- log(rgamma(100,a))
                      y <- log(rgamma(100,a))+ncp
                      adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)}))

x <- rt(100,4)
y <- rt(100,4)
adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)

mean(replicate(10000,{ncp <- .35
                      x <- rt(100,4)
                      y <- rt(100,4,ncp)
                      adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)}))

adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)

mean(replicate(10000,{sd <- 2.8
                      x <- rnorm_cont(100,0,sd,cshift=0,csd=3*sd)
                      y <- rnorm_cont(100,1,sd,cshift=1,csd=3*sd)
                      adaptive_invnormtest_2s(x,y,n1=50,n=100,ne=100)}))

```

```{r}
robust_pooled_variance <- function(x,y){
    (iqr(c(x-median(x),y-median(y)))/1.349)^2
}
cond_power_rule_t_ts <- function(x,y,delta=1,target=.9,alpha=0.025,maxN=length(x)*6,rob_var=T){
    n1 <- length(x)
    var <- ifelse(rob_var,
                  robust_pooled_variance(x,y),
                  pooled_variance(c(x,y),c(rep(0,length(x)),rep(1,length(y)))))
    nE <- 2*(qnorm(alpha,lower=F)+ qnorm(target))^2*var/(delta^2)
    min(maxN,nE)
}

```
```{r,eval=F}
mean(replicate(10000,{
                   sd <- 3.2
                   x <- rnorm(100,sd=sd)
                   y <- rnorm(100,m=1,sd=sd)
                   sqrt(robust_pooled_variance(x,y))}))

mean(replicate(10000,{
                   sd <- 3.2
                   x <- rnorm(100,sd=sd)
                   y <- rnorm(100,m=1,sd=sd)
                   sqrt(pooled_variance(c(x,y),rep(0:1,each=100)))}))

mean(replicate(10000,{ncp <- .35
                      x <- rt(100,4)*2.8
                      y <- rt(100,4,ncp)*2.8
                      sqrt(robust_pooled_variance(x,y))}))

mean(replicate(10000,{a <- 1
                      ncp <- .4
                      x <- log(rgamma(100,a))
                      y <- log(rgamma(100,a))+ncp
                      sqrt(robust_pooled_variance(x,y))}))

mean(replicate(10000,{ncp <- 1
                      x <- rnorm_cont(100,0,3.15,cshift=0,csd=3*3.15)
                      y <- rnorm_cont(100,ncp,3.15,cshift=ncp,csd=3*3.15)
                      sqrt(robust_pooled_variance(x,y))}))


mean(replicate(10000,{ncp <- 1
                      x <- rnorm_cont(100,0,3.15,cshift=0,csd=3*3.15)
                      y <- rnorm_cont(100,ncp,3.15,cshift=ncp,csd=3*3.15)
                      sqrt(pooled_variance(c(x,y),rep(0:1,each=100)))}))
                      


```
This concludes the configuration of the large sample setup.

In all situations our planning assumption is normally distributed
observations with mean difference of $\delta_0=1$ and common standard deviation
of $\sigma_0=2.5$. For these larger sample sizes there is almost no
difference in power between the the inverse normal combination and the
fixed sample t-test. We will simulate data from:

1. Normal distributions with mean-differences $\delta=1$ and $\sigma=3.2$
2. Log-gamma distirbiutions with shape parameter $a=1$ shifted by
   $\delta=.4$ in the treatment group
3. $t$-distributions with $4$ degrees of freedom and non-centrality
   parameter $.35$ in the treatment group

in all cases the inverse normal combination test has a (simulated)
power of 60%.


# Simulation study

```{r}



run_scenario <- function(scenario){
    with(scenario,{
             xdist = function(N) {
                 switch(distribution,
                        'normal'=rnorm(N,m=0,sd=parameter),
                        'log-gamma'=log(rgamma(N,1)),
                        't4'=rt(N,4),
                        'cont'=rnorm_cont(N,m=0,sd=parameter,cshift=0,csd=3*parameter),
                        'count'=)
             }
             ydist = function(N) {
                 switch(distribution,
                        'normal'=rnorm(N,m=delta0,sd=parameter),
                        'log-gamma'=log(rgamma(N,1))+delta0*parameter,
                        't4'=rt(N,4,ncp=delta0*parameter),
                        'cont'=rnorm_cont(N,m=delta0,sd=parameter,cshift=delta0,csd=3*parameter),
                        'count'=)
             }
             x1 <- xdist(n1)
             y1 <- ydist(n1)
             delta <- c('normal'=1,
                        'log-gamma'=parameter,
                        't4'=parameter,
                        'cont'=1)[distribution]
             nE <- max(n,cond_power_rule_t_ts(x1,y1,delta=delta,target=.8))
             
             n_combs <- choose(2*n1,n1)*choose(2*(n-n1),(n-n1))
             exact  <- n_combs>10^5
                                        #  <- ifelse(n_combs>10000,'davison_hinkley','midp')
             ttpe <- 'non-randomized'
             cete <- 'non-randomized'
             x <- c(x1,xdist(nE-n1))
             y <- c(y1,ydist(nE-n1))
             data_frame(
                 exact=exact,
                 nE=nE,
#                 fixed_t=perm_test(c(x[1:n1],y[1:n1]),c(x[(n1+1):n],y[(n1+1):n]),rep(0:1,each=n1),rep(0:1,each=n1),tstat,10^5,restricted=T)<=0.025,
#                 fixed_w=perm_test(c(x[1:n1],y[1:n1]),c(x[(n1+1):n],y[(n1+1):n]),rep(0:1,each=n1),rep(0:1,each=n1),ranksum,10^5,restricted=T)<=0.025,
                 invnorm_t=adaptive_invnormtest_2s(x,y,n1=n1,n=n,ne=nE),
                 invnorm_w=adaptive_invnorm_wilcoxtest_2s(x,y,n1=n1,n=n,ne=nE),
                 adaperm_t=adaperm_DR(c(x,y),rep(0:1,each=nE),n1=n1,n=n,test=tstat,cer_type=cete,atest_type=ttpe,permutations=10^5),
                 adaperm_rw=adaperm_DR(c(x,y),rep(0:1,each=nE),n1=n1,n=n,test=ranksum,cer_type='randomized',atest_type='non-randomized',permutations=10^5),
                 adaperm_rwp=adaperm_DR(c(x,y),rep(0:1,each=nE),n1=n1,n=n,test=ranksum,cer_type='randomized',atest_type='midp',permutations=10^5),
                 adaperm_w=adaperm_DR(c(x,y),rep(0:1,each=nE),n1=n1,n=n,test=ranksum,cer_type='non-randomized',atest_type='non-randomized',permutations=10^5))
                                        #             adaperm_m=adaperm_DR(c(x,y),rep(0:1,each=nE),n1=n1,n=n,test=maritzm,atest_type='davison_hinkley'))
         })
}

simulate_scenario <- function(scenario,B){
    bind_rows(mclapply2(1:B,function(i) run_scenario(scenario))) %>%
        summarise(B=B,
                  pExact = mean(exact),
                  ASN = mean(nE),
                  sdSN = sd(nE),
                  MSN = max(nE),
#                  fixed_t = mean(fixed_t),
#                  fixed_w = mean(fixed_w),
                  invnorm_t=mean(invnorm_t),
                  invnorm_w=mean(invnorm_w),
                  adaperm_t=mean(adaperm_t),
                  adaperm_w=mean(adaperm_w),
                  adaperm_rw=mean(adaperm_rw),
                  adaperm_rwp=mean(adaperm_rwp))
#                  adaperm_m=mean(adaperm_m))
}
```

```{r,eval=F}

scenarios <- data_frame(n1 = rep(c(rep(5,4),rep(50,4)),2),
                n =  rep(c(rep(10,4),rep(100,4)),2),
                distribution = rep(rep(c('normal','log-gamma','t4','cont'),2),2),
                        parameter = rep(c(.9,1.35,1.2,.8,
                            3.2,.4,.35,2.8),2),
                delta0 = rep(0:1,each=8),
                sigma0 = rep(rep(c(.6,2.5),each=4),2))
                
## simulate_scenario(scenarios[2,],1000)
## simulate_scenario(scenarios[10,],5000)
## run_scenario(scenarios[2,])
## run_scenario(scenarios[10,])
out <- list() 
for(i in c(9:12)) out[[i]] <- bind_cols(scenarios[i,],simulate_scenario(scenarios[i,],B=50000))
sims <- bind_rows(out)
#for(i in 1:nrow(scenarios)) out[[i]] <- bind_cols(scenarios[i,],simulate_scenario(scenarios[i,],B=20000))

save(sims,file=vfile('~/adaperm_simresults/alt_simulations'))


```

```{r}

load('../data/simulations_node5_160319.Rd')

pdf('simresults.pdf',height=4,width=7)
sims %>% mutate(distribution = relevel(factor(distribution),'normal')) %>%
    melt(.,id.vars=1:9,value.name='Power',variable.name='Test') %>% 
        ggplot(aes(distribution,Power,fill=Test))+geom_bar(stat='identity',position='dodge')+facet_grid(delta0~n1,scales='free_y')
dev.off()

sims %>% melt(.,id.vars=1:9,value.name='Power',variable.name='Test') %>%
    subset(delta0==0) %>% dcast(Test~n1+distribution,value.var='Power')


```


```{r simulations for pauly}
set.seed(10514)
library(flip)
B <- 1000
n <- 20
X0 <- matrix(rt(n*B,df=2),n)
X <- matrix(rt(n*B,df=2),n)+1


ttests0 <- apply(X0,2,t.test,alternative='greater')
ttests0_pvalues <- sapply(ttests0,`[[`,'p.value')
ttests <- apply(X,2,t.test,alternative='greater')
ttests_pvalues <- sapply(ttests,`[[`,'p.value')


comb10 <- apply(X0[1:(n/2),],2,t.test,alternative='greater')
comb10_pvalues <- sapply(comb10,`[[`,'p.value')
comb20 <- apply(X0[(n/2+1):n,],2,t.test,alternative='greater')
comb20_pvalues <- sapply(comb20,`[[`,'p.value')
comb0_pvalues <- pnorm(sqrt(.5)*(qnorm(comb10_pvalues,lower=F)+qnorm(comb20_pvalues,lower=F)),lower=F)

comb1 <- apply(X[1:(n/2),],2,t.test,alternative='greater')
comb1_pvalues <- sapply(comb1,`[[`,'p.value')
comb2 <- apply(X[(n/2+1):n,],2,t.test,alternative='greater')
comb2_pvalues <- sapply(comb2,`[[`,'p.value')
comb_pvalues <- pnorm(sqrt(.5)*(qnorm(comb1_pvalues,lower=F)+qnorm(comb2_pvalues,lower=F)),lower=F)

permtests0 <- flip(X0,statTest='t',tail=1,perms=10000)
permtests0_pvalues <- permtests0@res$`p-value`
permtests <- flip(X,statTest='t',tail=1,perms=10000)
permtests_pvalues <- permtests@res$`p-value`

wilctests0 <- flip(X0,statTest='Wilcoxon',tail=1,perms=10000)
wilctests0_pvalues <- wilctests0@res$`p-value`
wilctests <- flip(X,statTest='Wilcoxon',tail=1,perms=10000)
wilctests_pvalues <- wilctests@res$`p-value`

mean(ttests0_pvalues<=.05)
mean(permtests0_pvalues<=.05)
mean(comb0_pvalues<=.05)
mean(wilctests0_pvalues<=.05)

mean(ttests_pvalues<=.05)
mean(permtests_pvalues<=.05)
mean(comb_pvalues<=.05)
mean(wilctests_pvalues<=.05)

```
